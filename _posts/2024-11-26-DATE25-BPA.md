---
title: Best Paper Candidate
---

Our paper titled "ReBERT: LLM for Gate-Level to Word-Level Reverse Engineering" has been nominated for best paper in [DATE'2025](https://www.date-conference.com/). Congratulations to first author [Lizi Zhang](https://wiscad.github.io/wiscad/members/lizi-zhang.html) and thanks to our industry collaborator Dr. Rasit Topaloglu. This paper discusses an effective way to encode a a gate-level circuit given in a Hardware Description Language to reverse engineer the higher-level words using Large Language Models. We combine different embedding schemes to encode circuit information to best be inferred by the BERT model. This includes a novel tree-based positional embedding scheme to encode the position of each gate within the graph structure of a circuit as a token sequence.
